---
title: "Cross-Modal Adaptation for Object Detection in InfraRed Remote Sensing Imagery"
collection: publications
permalink: /publication/2024_UP_Diff_Latent_Diffusion_Model_for_Remote_Sensing_Urban_Prediction
excerpt: '__Zeyu Wang__, Shuaiting Li, Kejie Huang'
date: 2024-07-15
venue: 'IEEE Geoscience and Remote Sensing Letters (GRSL)'
---

__Abstract:__Modern InfraRed (IR) technology has been proven highly significant in Remote Sensing Imagery (RSI).
Currently, multimodal RSI object detection based on RGB-IR image pairs has attracted widespread research.
However, capturing features in the IR domain poses a challenge, as existing object detectors heavily focus on chromatic information in the RGB domain.
Furthermore, the quality of RGB images can be influenced by complex environmental conditions, limiting the practicality of multimodal detection.
In this paper, we introduce Cross-Modal-YOLO (CM-YOLO), a lightweight yet effective object detector specifically designed for IR remote sensing images.
CM-YOLO employs cross-modal adaptation to enhance the awareness of IR-RGB modality translation.
Specifically, we leverage a Prior Modality Translator (PMT) to learn the InfraRed-Visible (IV) features, which are incorporated into the detection backbone using our IV-Gate modules.
Experimental results on the VEDAI dataset demonstrate that CM-YOLO significantly outperforms conventional methods.
Moreover, CM-YOLO exhibits a strong generalization ability for IR-based object detection in urban scenes on the FLIR dataset.
